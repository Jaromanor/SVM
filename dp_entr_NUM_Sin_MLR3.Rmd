---
title: "SVM"
author: "JARO"
date: "2025-05-20"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
library(CDR)
library(caret)
library(ggplot2)
library(e1071)
library(dplyr)
```


# 1. CONTEXTO

Se realzar√° un ejercicio utilizando caret. Se usar√° una data que pretende vender tensi√≥metros digitales, obteni√©ndose las predicciones sobre si el cliente comprar√° o no un tensi√≥metro en funci√≥n de una serie de variables incluidas en el conjunto de datos dp_ENTRdel paquete CDR.

# 2. CARGA DE DATOS

```{r}
data(dp_entr_NUM)
str(dp_entr_NUM)
```

# 3. PARTICI√ìN

```{r}
set.seed(123)
trainIndex<-createDataPartition(
  dp_entr_NUM$CLS_PRO_pro13,
  p=0.8,
  list = FALSE)
trainData<-dp_entr_NUM[trainIndex,]
testData<-dp_entr_NUM[-trainIndex,]
```


# 5. ENTRENAMIENTO CON CV y PREPROCESAMIENTO

Se van a predecir probabilidades, entonces es necesario poner classProbs como TRUE. Las m√©tricas para cv son roc, sens y espec. Entonces se debe indicar summaryFunction = twoClassSummary y tener en cuenta cuando se vaya entrenar el modelo escoger metrica: ROC

```{r}
ctrl<-trainControl(
  method = "cv",
  number = 10,
  classProbs = TRUE,
  summaryFunction = twoClassSummary #calcula roc, sens y especi
)
```

```{r}
set.seed(123)
modelo_svm<-train(
  CLS_PRO_pro13~.,
  data=trainData,
  method="svmRadial",
  metric = "ROC",                 # M√©trica para optimizar
  preProcess = c("center", "scale"),
  tuneLength = 5,                 # Prueba 5 combinaciones de C y sigma
  trControl = ctrl
)

print(modelo_svm)
plot(modelo_svm)
```




qu√© combinaciones se probaron con:
```{r}
modelo_svm$results
```

Y el mejor modelo con:
```{r}
modelo_svm$bestTune
```

El modelo utilizado es una M√°quina de Vectores de Soporte (SVM) con un kernel radial (RBF)

448 observaciones fueron usadas en el entrenamiento.

El modelo considera 19 variables predictoras.

Es una tarea de clasificaci√≥n binaria: la variable de salida tiene 2 clases:

'S': Positivo

'N': Negativo

Todas las variables fueron centradas (media 0) y escaladas (desviaci√≥n est√°ndar 1).

Se us√≥ validaci√≥n cruzada de 10 particiones (10-fold CV) para estimar el rendimiento del modelo.

Cada fold us√≥ entre 402‚Äì404 muestras para entrenamiento, y el resto para validaci√≥n interna.

Se evaluaron 5 valores del hiperpar√°metro C (el par√°metro de penalizaci√≥n por error). Para cada valor se reportan:

ROC (√Årea bajo la curva ROC): mide la capacidad de discriminaci√≥n del modelo (cuanto m√°s alto, mejor).

Sens (Sensibilidad): tasa de verdaderos positivos (recall de la clase 'S').

Spec (Especificidad): tasa de verdaderos negativos (recall de la clase 'N').

El mejor valor de ROC = 0.9439 se logr√≥ con C = 0.25.

sigma es el par√°metro del kernel radial (controla la forma de la funci√≥n de decisi√≥n). En esta b√∫squeda se mantuvo fijo.

La selecci√≥n del mejor modelo se bas√≥ en la m√°xima AUC (ROC).

El modelo final usar√°:

C = 0.25: penalizaci√≥n ligera, m√°s flexible

sigma = 0.034: cierta capacidad para captar no linealidad sin sobreajuste



El modelo SVM con kernel RBF mostr√≥ excelente rendimiento predictivo, con AUC cercano a 0.94


C: Este hiperpar√°metro controla el equilibrio entre el margen del modelo y los errores de clasificaci√≥n en el entrenamiento.

Conceptualmente:
Valor bajo (C = 0.25):

Permite m√°s errores en el entrenamiento.

Tiende a m√°rgenes m√°s amplios, lo que reduce el sobreajuste.

El modelo es m√°s simple y generaliza mejor, pero puede cometer m√°s errores con los datos de entrenamiento.

Valor alto (ej. C = 10):

Penaliza mucho los errores ‚Üí m√°rgenes estrechos.

Tiende a sobreajustar si hay ruido en los datos.

Mejor en entrenamiento, pero puede fallar en test.

C = 0.25 sugiere que el modelo prioriza la simplicidad y generalizaci√≥n, permitiendo algunos errores en el entrenamiento para evitar sobreajuste.


En el kernel radial, sigma controla la influencia de cada punto de entrenamiento. Est√° relacionado con gamma = 1 / (2 * sigma¬≤).

Conceptualmente:
Valor peque√±o de sigma (ej. 0.01):

La influencia de cada punto es muy localizada.

La funci√≥n de decisi√≥n se vuelve muy curva y compleja ‚Üí riesgo de sobreajuste.

Valor grande de sigma (ej. 0.5 o 1):

La influencia se distribuye m√°s ampliamente.

La funci√≥n de decisi√≥n es m√°s suave, pero puede perder capacidad para distinguir clases complejas.

üßæ En tu resultado:
sigma = 0.034 est√° en un rango medio-bajo, lo que permite al modelo capturar ciertas no linealidades pero sin volverse tan sensible a puntos individuales (lo cual causar√≠a sobreajuste).



Respecto al gr√°fico:
¬øQu√© observamos?
El mejor valor de ROC (~0.944) se alcanza cuando C = 0.25 (m√°s a la izquierda).

A medida que C aumenta (hacia la derecha), el ROC disminuye ligeramente, alcanzando un m√≠nimo alrededor de C = 2, y luego sube un poco en C = 4.

La forma de la curva sugiere una ligera U invertida, donde los extremos (especialmente C bajo) funcionan mejor que el medio.

El gr√°fico indica que el modelo SVM logra su mejor capacidad de discriminaci√≥n (AUC) con un valor de penalizaci√≥n bajo (C = 0.25). Esto sugiere que un margen m√°s amplio, con cierta tolerancia a errores de clasificaci√≥n en el entrenamiento, produce mejores resultados en validaci√≥n cruzada, es decir, generaliza mejor a nuevos datos.


# 8. EVALUACI√ìN

```{r}
pred<-predict(modelo_svm,newdata=testData)
confusionMatrix(pred,testData$CLS_PRO_pro13)

# AUC
pred_prob <- predict(modelo_svm, newdata = testData, type = "prob")
library(pROC)
roc <- roc(response = testData$CLS_PRO_pro13,
           predictor = pred_prob$S,
           levels = rev(levels(testData$CLS_PRO_pro13)))
auc_value<-auc(roc)
```



```{r}
ggplot() +
  geom_line(aes(x = 1 - roc$specificities, y = roc$sensitivities), 
            color = "darkorange", linewidth = 1) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "gray") +
  labs(x = "1 - Especificidad (Falsos Positivos)", 
       y = "Sensibilidad (Verdaderos Positivos)",
       title = paste("Curva ROC - AUC =", round(auc_value, 4))) +
  theme_minimal()
```






# 9. EXPORTACI√ìN MODELO PARA PRODUCCI√ìN


```{r}
saveRDS(modelo_svm, "modelo_svm_compra.rds")

```


```{r}
modelo_cargado <- readRDS("modelo_svm_compra.rds")
predict(modelo_cargado, newdata = nuevos_datos)
```













